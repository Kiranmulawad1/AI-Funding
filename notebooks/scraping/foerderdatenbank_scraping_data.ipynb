{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ae2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Imports ---\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a77760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Setup WebDriver ---\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bfbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "No forward button found or last page reached.\n",
      "Total links collected: 34\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Collect Program Links from All Pages ---\n",
    "base_url = \"https://www.foerderdatenbank.de/SiteGlobals/FDB/Forms/Suche/Foederprogrammsuche_Formular.html?resourceId=0065e6ec-5c0a-4678-b503-b7e7ec435dfd&input_=23adddb0-dcf7-4e32-96f5-93aec5db2716&pageLocale=de&filterCategories=FundingProgram&templateQueryString=KI&submit=Suchen\"\n",
    "driver.get(base_url)\n",
    "\n",
    "all_links = []\n",
    "\n",
    "for page_num in range(1, 6):\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"p.card--title a\"))\n",
    "    )\n",
    "\n",
    "    funding_elements = driver.find_elements(By.CSS_SELECTOR, \"p.card--title a\")\n",
    "    for element in funding_elements:\n",
    "        link = element.get_attribute(\"href\")\n",
    "        if link and link not in all_links:\n",
    "            all_links.append(link)\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, \"a.forward.button\")\n",
    "        next_page_url = next_button.get_attribute(\"href\")\n",
    "        if next_page_url:\n",
    "            driver.get(next_page_url)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            print(\"No further pages found. Stopping.\")\n",
    "            break\n",
    "    except Exception:\n",
    "        print(\"No forward button found or last page reached.\")\n",
    "        break\n",
    "\n",
    "print(f\"Total links collected: {len(all_links)}\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8701cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Define extraction logic ---\n",
    "def extract_features(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        name = soup.find(\"h1\", class_=\"title\")\n",
    "        name = name.text.strip() if name else \"Name information not found.\"\n",
    "\n",
    "        desc_div = soup.find(\"div\", class_=\"rich--text\")\n",
    "        description = desc_div.find(\"p\").text.strip() if desc_div and desc_div.find(\"p\") else \"Description information not found.\"\n",
    "\n",
    "        domain_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rderbereich\"))\n",
    "        domain = domain_dt.find_next(\"dd\").text.strip() if domain_dt else \"Domain information not found.\"\n",
    "\n",
    "        eligibility_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rderberechtigte\"))\n",
    "        eligibility = eligibility_dt.find_next(\"dd\").text.strip() if eligibility_dt else \"Eligibility information not found.\"\n",
    "\n",
    "        location_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rdergebiet\"))\n",
    "        location = location_dt.find_next(\"dd\").text.strip() if location_dt else \"Location information not found.\"\n",
    "\n",
    "        contact_dt = soup.find(\"dt\", string=re.compile(\"Ansprechpunkt\"))\n",
    "        if contact_dt:\n",
    "            contact_info = contact_dt.find_next(\"dd\")\n",
    "            contact_name = contact_info.find(\"span\", class_=\"link--label\")\n",
    "            contact_email = contact_info.find(\"a\", href=lambda x: x and \"mailto\" in x)\n",
    "            contact_phone = contact_info.find(\"p\", class_=\"tel\")\n",
    "            contact_address = contact_info.find(\"p\", class_=\"locality\")\n",
    "            contact = f\"Name: {contact_name.text.strip() if contact_name else 'N/A'}, Email: {contact_email.text.strip() if contact_email else 'N/A'}, Phone: {contact_phone.text.strip() if contact_phone else 'N/A'}, Address: {contact_address.text.strip() if contact_address else 'N/A'}\"\n",
    "        else:\n",
    "            contact = \"Contact information not found.\"\n",
    "\n",
    "        return [name, description, domain, eligibility, location, contact, url]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return [\"Error\"] * 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd3684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/KultStiftBund/kunst-und-ki.html\n",
      "Processing 2/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/anwendung-ki-wirkstoffforschung.html\n",
      "Processing 3/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/NRW/next-in-nrw.html\n",
      "Processing 4/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/zukunft-wertschoepfung-deutschland.html\n",
      "Processing 5/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/bmbf-neurobiologisch-inspirierte-ki.html\n",
      "Processing 6/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/bmbf_mathematik_fuer_innovationen.html\n",
      "Processing 7/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/projekte-zum-thema-6-g-in-die-anwendung-bringen.html\n",
      "Processing 8/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/selbstaendige-forschungsgruppen-zukunft-ehealth.html\n",
      "Processing 9/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/bmbf_biotechnologie_ki_biodiversitaetsforschung.html\n",
      "Processing 10/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMWi/greentech-innovationswettbewerb-862422.html\n",
      "Processing 11/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/data-xperiment.html\n",
      "Processing 12/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/EU/digitales-europa.html\n",
      "Processing 13/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Baden-Wuerttemberg/digitalisierungspraemie-plus-zuschussvariante.html\n",
      "Processing 14/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/richtlinie-zur-foerderung-von-zuwendungen-fuer-di.html\n",
      "Processing 15/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/klimaanpassung-urbane-digitale-zwillinge.html\n",
      "Processing 16/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/biomedizin.html\n",
      "Processing 17/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/NRW/nrw-bank-venture-fonds.html\n",
      "Processing 18/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMWi/entwicklung-digitaler-technologien.html\n",
      "Processing 19/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMAS/sicherheit-gesundheit-wandel-arbeitswelt.html\n",
      "Processing 20/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Niedersachsen/staerkung-der-ambulanten-pflege-land.html\n",
      "Processing 21/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMAS/zukunftszentren-kmu-digitale-transformation-2.html\n",
      "Processing 22/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/software-algorithmen-ki-maschinelles-lernen.html\n",
      "Processing 23/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/NRW/neue-wege-in-nrw.html\n",
      "Processing 24/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Sachsen/esf-hochschule-und-forschung-promotionen.html\n",
      "Processing 25/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Sachsen/esf-hochschule-und-forschung-nachwuchs.html\n",
      "Processing 26/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Baden-Wuerttemberg/tourismusfinanzierung-plus.html\n",
      "Processing 27/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/NRW/energie-in-nrw.html\n",
      "Processing 28/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Baden-Wuerttemberg/digitalisierungspraemie-plus-darlehensvariante.html\n",
      "Processing 29/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Sachsen-Anhalt/richtlinie-forst-2019.html\n",
      "Processing 30/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Saarland/foerderung-von-forschung.html\n",
      "Processing 31/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/mikroelektronik-verbundpartner-kdt.html\n",
      "Processing 32/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/forka.html\n",
      "Processing 33/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/zuwendungen-nukleare-sicherheits-strahlenforschung.html\n",
      "Processing 34/34: https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Land/Rheinland-Pfalz/foerderrichtlinien-wasserwirtschaftsverwaltung.html\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Extract features from all links ---\n",
    "data = []\n",
    "for i, link in enumerate(all_links):\n",
    "    print(f\"Processing {i + 1}/{len(all_links)}: {link}\")\n",
    "    features = extract_features(link)\n",
    "    data.append(features)\n",
    "    time.sleep(1.5)  # avoid hammering the server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8871174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data saved to data/funding-foerderdatenbank-data.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Save to CSV ---\n",
    "columns = [\"name\", \"description\", \"domain\", \"eligibility\", \"location\", \"contact\", \"url\"]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "output_path = \"data/funding-foerderdatenbank-data.csv\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% [markdown]\n",
    "# # # ðŸš€ FÃ¶rderdatenbank Scraper (Improved Version)\n",
    "\n",
    "# # %%\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# import time\n",
    "# import os\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # %%\n",
    "# # --- Config ---\n",
    "# BASE_URL = \"https://www.foerderdatenbank.de/SiteGlobals/FDB/Forms/Suche/Foederprogrammsuche_Formular.html?resourceId=0065e6ec-5c0a-4678-b503-b7e7ec435dfd&input_=23adddb0-dcf7-4e32-96f5-93aec5db2716&pageLocale=de&filterCategories=FundingProgram&templateQueryString=KI&submit=Suchen\"\n",
    "# OUTPUT_DIR = \"data\"\n",
    "# OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"funding-foerderdatenbank-data.csv\")\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# # %%\n",
    "# # --- Setup WebDriver ---\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')\n",
    "# options.add_argument('--no-sandbox')\n",
    "# options.add_argument('--disable-dev-shm-usage')\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# # %%\n",
    "# # --- Collect Program Links from All Pages ---\n",
    "# all_links = set()\n",
    "# page_num = 1\n",
    "# driver.get(BASE_URL)\n",
    "\n",
    "# while True:\n",
    "#     print(f\"Scraping page {page_num}...\")\n",
    "#     try:\n",
    "#         WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"p.card--title a\"))\n",
    "#         )\n",
    "#         funding_elements = driver.find_elements(By.CSS_SELECTOR, \"p.card--title a\")\n",
    "#         for element in funding_elements:\n",
    "#             link = element.get_attribute(\"href\")\n",
    "#             if link:\n",
    "#                 all_links.add(link)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error on page {page_num}: {e}\")\n",
    "#         break\n",
    "\n",
    "#     try:\n",
    "#         next_button = driver.find_element(By.CSS_SELECTOR, \"a.forward.button\")\n",
    "#         next_page_url = next_button.get_attribute(\"href\")\n",
    "#         if next_page_url:\n",
    "#             driver.get(next_page_url)\n",
    "#             page_num += 1\n",
    "#             time.sleep(2)\n",
    "#         else:\n",
    "#             print(\"No further pages found. Stopping.\")\n",
    "#             break\n",
    "#     except Exception:\n",
    "#         print(\"No forward button found or last page reached.\")\n",
    "#         break\n",
    "\n",
    "# print(f\"Total links collected: {len(all_links)}\")\n",
    "# driver.quit()\n",
    "\n",
    "# # %%\n",
    "# # --- Define Extraction Logic ---\n",
    "# def extract_features(url):\n",
    "#     try:\n",
    "#         response = requests.get(url, timeout=10)\n",
    "#         response.raise_for_status()\n",
    "#         soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "#         name = soup.find(\"h1\", class_=\"title\")\n",
    "#         name = name.text.strip() if name else \"\"\n",
    "\n",
    "#         desc_div = soup.find(\"div\", class_=\"rich--text\")\n",
    "#         description = desc_div.find(\"p\").text.strip() if desc_div and desc_div.find(\"p\") else \"\"\n",
    "\n",
    "#         domain_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rderbereich\"))\n",
    "#         domain = domain_dt.find_next(\"dd\").text.strip() if domain_dt else \"\"\n",
    "\n",
    "#         eligibility_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rderberechtigte\"))\n",
    "#         eligibility = eligibility_dt.find_next(\"dd\").text.strip() if eligibility_dt else \"\"\n",
    "\n",
    "#         location_dt = soup.find(\"dt\", string=re.compile(\"F\\u00f6rdergebiet\"))\n",
    "#         location = location_dt.find_next(\"dd\").text.strip() if location_dt else \"\"\n",
    "\n",
    "#         contact_dt = soup.find(\"dt\", string=re.compile(\"Ansprechpunkt\"))\n",
    "#         if contact_dt:\n",
    "#             contact_info = contact_dt.find_next(\"dd\")\n",
    "#             contact_name = contact_info.find(\"span\", class_=\"link--label\")\n",
    "#             contact_email = contact_info.find(\"a\", href=lambda x: x and \"mailto\" in x)\n",
    "#             contact_phone = contact_info.find(\"p\", class_=\"tel\")\n",
    "#             contact_address = contact_info.find(\"p\", class_=\"locality\")\n",
    "#             contact = f\"Name: {contact_name.text.strip() if contact_name else 'N/A'}, Email: {contact_email.text.strip() if contact_email else 'N/A'}, Phone: {contact_phone.text.strip() if contact_phone else 'N/A'}, Address: {contact_address.text.strip() if contact_address else 'N/A'}\"\n",
    "#         else:\n",
    "#             contact = \"\"\n",
    "\n",
    "#         return [name, description, domain, eligibility, location, contact, url]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {url}: {e}\")\n",
    "#         return [\"\"] * 7\n",
    "\n",
    "# # %%\n",
    "# # --- Extract features from all links ---\n",
    "# data = []\n",
    "# all_links_list = list(all_links)\n",
    "# for i, link in enumerate(tqdm(all_links_list, desc=\"Scraping details\")):\n",
    "#     features = extract_features(link)\n",
    "#     data.append(features)\n",
    "#     time.sleep(1.2)  # be nice to the server\n",
    "\n",
    "# # %%\n",
    "# # --- Save to CSV ---\n",
    "# columns = [\"name\", \"description\", \"domain\", \"eligibility\", \"location\", \"contact\", \"url\"]\n",
    "# df = pd.DataFrame(data, columns=columns)\n",
    "# df.to_csv(OUTPUT_FILE, index=False)\n",
    "# print(f\"âœ… Data saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# # %%\n",
    "# df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
