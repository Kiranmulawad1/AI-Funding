{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd89359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Install required packages (if not already installed)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -q openai pinecone python-dotenv pandas tqdm tenacity tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6da0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29ee60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "assert OPENAI_API_KEY, \"❌ OPENAI_API_KEY not found in .env\"\n",
    "assert PINECONE_API_KEY, \"❌ PINECONE_API_KEY not found in .env\"\n",
    "assert PINECONE_ENV, \"❌ PINECONE_ENV not found in .env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbb06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize OpenAI and Pinecone clients\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"funding-search\"\n",
    "dimension = 1536  # OpenAI embedding size for text-embedding-3-small\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "    )\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfa3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load funding dataset\n",
    "df = pd.read_csv(\"/Users/kiranmulawad/AI-Funding/2_preprocessing/data/merged_funding_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f198ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Build semantic_corpus from multiple fields with labeled formatting\n",
    "def build_semantic_corpus(row):\n",
    "    name = row.get(\"name\", \"\")\n",
    "    description = row.get(\"description\", \"\")\n",
    "    domain = row.get(\"domain\", \"\")\n",
    "    eligibility = row.get(\"eligibility\", \"\")\n",
    "    amount = row.get(\"amount\", \"\")\n",
    "    location = row.get(\"location\", \"\")\n",
    "    procedure = row.get(\"procedure\", \"\")\n",
    "    contact = row.get(\"contact\", \"\")\n",
    "    deadline = row.get(\"deadline\", \"\")\n",
    "\n",
    "    return \". \".join([\n",
    "        f\"name = {name}\" if name else \"\",\n",
    "        f\"description = {description}\" if description else \"\",\n",
    "        f\"domain = {domain}\" if domain else \"\",\n",
    "        f\"eligibility = {eligibility}\" if eligibility else \"\",\n",
    "        f\"amount = {amount}\" if amount else \"\",\n",
    "        f\"location = {location}\" if location else \"\",\n",
    "        f\"procedure = {procedure}\" if procedure else \"\",\n",
    "        f\"contact = {contact}\" if contact else \"\",\n",
    "        f\"deadline = {deadline}\" if deadline else \"\",\n",
    "    ]).strip(\". \")\n",
    "\n",
    "df[\"semantic_corpus\"] = df.apply(build_semantic_corpus, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e522b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Count tokens per row to avoid OpenAI 8192-token limit\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "df[\"token_count\"] = df[\"semantic_corpus\"].apply(lambda text: len(tokenizer.encode(text)))\n",
    "\n",
    "# Optional: Drop or warn for rows with too many tokens\n",
    "max_token_limit = 8192\n",
    "too_long = df[df[\"token_count\"] > max_token_limit]\n",
    "if not too_long.empty:\n",
    "    print(f\"⚠️ WARNING: {len(too_long)} rows exceed {max_token_limit} tokens. Consider truncating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "213f351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate stable hash-based IDs from URL\n",
    "def hash_id(text):\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "df[\"id\"] = df[\"url\"].fillna(\"no-url\").apply(hash_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c267432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Embed text with retry for rate limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb62a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading embeddings to Pinecone: 100%|██████████| 3/3 [00:30<00:00, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All OpenAI embeddings uploaded to Pinecone under namespace: openai-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Upsert embeddings to Pinecone in batches\n",
    "batch_size = 32\n",
    "namespace = \"openai-v3\"\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size), desc=\"Uploading embeddings to Pinecone\"):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    texts = batch[\"semantic_corpus\"].fillna(\"\").tolist()\n",
    "    ids = batch[\"id\"].tolist()\n",
    "    embeddings = [get_embedding(text) for text in texts]\n",
    "    \n",
    "    metadata = batch[[\n",
    "        \"id\", \"name\", \"description\", \"domain\", \"eligibility\", \"location\",\n",
    "        \"amount\", \"procedure\", \"contact\", \"deadline\", \"url\"\n",
    "    ]].fillna(\"\").to_dict(orient=\"records\")\n",
    "    \n",
    "    vectors = list(zip(ids, embeddings, metadata))\n",
    "    \n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "\n",
    "print(\"✅ All OpenAI embeddings uploaded to Pinecone under namespace:\", namespace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1b2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
