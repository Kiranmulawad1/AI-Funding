{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Install required packages (if you haven't)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -q openai tiktoken python-dotenv tqdm pandas pinecone fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4864974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fda737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz\n",
    "# print(fitz.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315dea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f639712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "assert OPENAI_API_KEY, \"Missing OPENAI_API_KEY\"\n",
    "assert PINECONE_API_KEY, \"Missing PINECONE_API_KEY\"\n",
    "assert PINECONE_ENV, \"Missing PINECONE_ENV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8f8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize clients\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "index_name = \"funding-search\"\n",
    "\n",
    "# Check/create index if needed\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI text-embedding-3-small dimension\n",
    "        metric=\"cosine\",\n",
    "        environment=PINECONE_ENV,\n",
    "    )\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6620429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load full funding dataset (for keyword backup and relevance scoring)\n",
    "full_df = pd.read_csv(\"/Users/kiranmulawad/AI-Funding/2_preprocessing/data/merged_funding_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ea62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# (Optional) Extract PDF profile text function, if using PDF profile to generate queries\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \"\\n\".join([page.get_text() for page in doc])\n",
    "\n",
    "# Example usage:\n",
    "# pdf_path = \"/path/to/sample_user_profile.pdf\"\n",
    "# pdf_text = extract_text_from_pdf(pdf_path)\n",
    "# print(\"PDF Text Sample:\", pdf_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e011b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# You can either generate a query automatically from user profile text or set manually\n",
    "# Example manual query string (replace with dynamic generation if you wish)\n",
    "query = \"We are an AI company focused on AI for robotics. We are focusing on research right now.\"\n",
    "user_location = \"Rhineland-Palatinate\"  # Or adapt as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba3f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Step 1: Embed the query with OpenAI embedding model\n",
    "query_embedding = client.embeddings.create(\n",
    "    input=[query],\n",
    "    model=\"text-embedding-3-small\"\n",
    ").data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1fefc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Step 2: Semantic search with Pinecone\n",
    "namespace = \"openai-v3\"  # use your correct namespace here\n",
    "top_k = 5\n",
    "\n",
    "semantic_matches = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=top_k,\n",
    "    include_metadata=True,\n",
    "    namespace=namespace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "836cebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Low semantic match score (<0.6), switching to keyword fallback...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Step 3: Check semantic score, fallback to keyword filter if too low\n",
    "top_score = max(match[\"score\"] for match in semantic_matches[\"matches\"]) if semantic_matches[\"matches\"] else 0\n",
    "\n",
    "def hybrid_keyword_filter(df, query, top_k=5):\n",
    "    keywords = set(re.findall(r'\\b\\w+\\b', query.lower()))\n",
    "    matched_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        combined_text = \" \".join([\n",
    "            str(row.get(col, \"\")).lower()\n",
    "            for col in [\"name\", \"description\", \"domain\", \"eligibility\"]\n",
    "        ])\n",
    "        if any(word in combined_text for word in keywords):\n",
    "            matched_rows.append(row)\n",
    "    return pd.DataFrame(matched_rows).head(top_k)\n",
    "\n",
    "if top_score < 0.6:\n",
    "    print(\"⚠️ Low semantic match score (<0.6), switching to keyword fallback...\")\n",
    "    results_df = hybrid_keyword_filter(full_df, query, top_k=top_k)\n",
    "else:\n",
    "    results_df = pd.DataFrame([m[\"metadata\"] for m in semantic_matches[\"matches\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccef58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone query matches count: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pinecone query matches count: {len(semantic_matches['matches'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c20319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pinecone matches: 5\n",
      "Rows before cleaning: 5\n",
      "Deadline parsing preview:\n",
      "        deadline deadline_date  days_left\n",
      "0  July 16, 2025    2025-07-16      -14.0\n",
      "1            NaN           NaT        NaN\n",
      "2  June 04, 2025    2025-06-04      -56.0\n",
      "3            NaN           NaT        NaN\n",
      "4  June 12, 2025    2025-06-12      -48.0\n",
      "Rows after filtering deadlines (keep missing + future): 2\n",
      "                         amount  \\\n",
      "1  amount information not found   \n",
      "3  amount information not found   \n",
      "\n",
      "                                             contact deadline  \\\n",
      "1  Name: Projektträger Jülich (PtJ), Email: ptj@f...      NaN   \n",
      "3  Name: DLR Projektträger, Email: ge@dlr.de, Pho...      NaN   \n",
      "\n",
      "                                         description  \\\n",
      "1  Guideline for the funding of projects on the t...   \n",
      "3  Guideline for the funding of interdisciplinary...   \n",
      "\n",
      "                                              domain  \\\n",
      "1  Research & Innovation (topic-specific), Health...   \n",
      "3             Research & Innovation (topic-specific)   \n",
      "\n",
      "                                         eligibility  \\\n",
      "1  University, research institution, company, ass...   \n",
      "3          Research institution, university, company   \n",
      "\n",
      "                                 id    location  \\\n",
      "1  cd21459049ca19b22a72fffcda329c79  Nationwide   \n",
      "3  7f11351b7489d381f3c2e474b06d25eb  Nationwide   \n",
      "\n",
      "                                                name  \\\n",
      "1  Funding for projects on the topic of \"Applicat...   \n",
      "3  Promotion of interdisciplinary pilot projects ...   \n",
      "\n",
      "                         procedure            source  \\\n",
      "1  procedure information not found  foerderdatenbank   \n",
      "3  procedure information not found  foerderdatenbank   \n",
      "\n",
      "                                                 url deadline_date  days_left  \n",
      "1  https://www.foerderdatenbank.de/FDB/Content/DE...           NaT        NaN  \n",
      "3  https://www.foerderdatenbank.de/FDB/Content/DE...           NaT        NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "def safe_parse_deadline(deadline_str):\n",
    "    try:\n",
    "        if pd.isna(deadline_str) or deadline_str.strip() == \"\":\n",
    "            return None\n",
    "        # Parse with dayfirst=True and fuzzy parsing to handle many date formats\n",
    "        return parser.parse(deadline_str, dayfirst=True, fuzzy=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Suppose `semantic_matches` is from your Pinecone query result\n",
    "# e.g. semantic_matches = index.query(...)\n",
    "\n",
    "print(f\"Total Pinecone matches: {len(semantic_matches['matches'])}\")\n",
    "\n",
    "# Build DataFrame from metadata extracted from Pinecone matches\n",
    "results_df = pd.DataFrame([m[\"metadata\"] for m in semantic_matches[\"matches\"]])\n",
    "\n",
    "print(f\"Rows before cleaning: {len(results_df)}\")\n",
    "\n",
    "# Replace placeholders indicating missing data with NaN for better handling\n",
    "placeholder_values = [\n",
    "    \"deadline information not found\",\n",
    "    \"amount information not found\",\n",
    "    \"contact information not found\",\n",
    "    \"procedure information not found\",\n",
    "    \"location information not found\",\n",
    "    \"\"  # empty string too\n",
    "]\n",
    "\n",
    "results_df[\"deadline\"] = results_df[\"deadline\"].replace(placeholder_values, np.nan)\n",
    "results_df[\"deadline\"] = results_df[\"deadline\"].infer_objects(copy=False)\n",
    "\n",
    "# Parse deadlines\n",
    "results_df[\"deadline_date\"] = results_df[\"deadline\"].apply(safe_parse_deadline)\n",
    "\n",
    "# Convert to pandas datetime to ensure proper dtype and facilitate date operations\n",
    "results_df[\"deadline_date\"] = pd.to_datetime(results_df[\"deadline_date\"], errors=\"coerce\")\n",
    "\n",
    "# Calculate days left until deadline\n",
    "results_df[\"days_left\"] = (results_df[\"deadline_date\"] - datetime.now()).dt.days\n",
    "\n",
    "print(\"Deadline parsing preview:\")\n",
    "print(results_df[[\"deadline\", \"deadline_date\", \"days_left\"]].head())\n",
    "\n",
    "# Filter rows: keep those with missing deadlines or with deadline in the future (days_left >= 0)\n",
    "results_df = results_df[\n",
    "    (results_df[\"days_left\"].isna()) | (results_df[\"days_left\"] >= 0)\n",
    "]\n",
    "\n",
    "print(f\"Rows after filtering deadlines (keep missing + future): {len(results_df)}\")\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"⚠️ Warning: No relevant rows remain after deadline filtering.\")\n",
    "else:\n",
    "    print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b951a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Step 5: Compute custom relevance scores, including location boost\n",
    "def compute_relevance_score(row, query, funding_need=200000, target_domain=\"AI\", user_location=\"Rhineland-Palatinate\"):\n",
    "    score = 0.0\n",
    "\n",
    "    # Domain match boost\n",
    "    if target_domain.lower() in str(row.get(\"domain\", \"\")).lower():\n",
    "        score += 0.4\n",
    "\n",
    "    # Funding amount boost\n",
    "    try:\n",
    "        amount_val = int(re.sub(r'[^\\d]', '', str(row.get(\"amount\", \"0\"))))\n",
    "        if amount_val >= funding_need:\n",
    "            score += 0.3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Deadline relevance boost\n",
    "    if \"month\" in str(row.get(\"deadline\", \"\")).lower() or \"2025\" in str(row.get(\"deadline\", \"\")):\n",
    "        score += 0.2\n",
    "\n",
    "    # Keyword presence in description\n",
    "    if any(word.lower() in str(row.get(\"description\", \"\")).lower() for word in query.split()):\n",
    "        score += 0.1\n",
    "\n",
    "    # User location boost\n",
    "    if user_location.lower() in str(row.get(\"location\", \"\")).lower():\n",
    "        score += 0.1\n",
    "\n",
    "    return round(score * 100)\n",
    "\n",
    "results_df[\"relevance_score\"] = results_df.apply(\n",
    "    lambda r: compute_relevance_score(r, query, user_location=user_location),\n",
    "    axis=1\n",
    ")\n",
    "results_df = results_df.sort_values(by=\"relevance_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50619a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         amount  \\\n",
      "1  amount information not found   \n",
      "3  amount information not found   \n",
      "\n",
      "                                             contact deadline  \\\n",
      "1  Name: Projektträger Jülich (PtJ), Email: ptj@f...      NaN   \n",
      "3  Name: DLR Projektträger, Email: ge@dlr.de, Pho...      NaN   \n",
      "\n",
      "                                         description  \\\n",
      "1  Guideline for the funding of projects on the t...   \n",
      "3  Guideline for the funding of interdisciplinary...   \n",
      "\n",
      "                                              domain  \\\n",
      "1  Research & Innovation (topic-specific), Health...   \n",
      "3             Research & Innovation (topic-specific)   \n",
      "\n",
      "                                         eligibility  \\\n",
      "1  University, research institution, company, ass...   \n",
      "3          Research institution, university, company   \n",
      "\n",
      "                                 id    location  \\\n",
      "1  cd21459049ca19b22a72fffcda329c79  Nationwide   \n",
      "3  7f11351b7489d381f3c2e474b06d25eb  Nationwide   \n",
      "\n",
      "                                                name  \\\n",
      "1  Funding for projects on the topic of \"Applicat...   \n",
      "3  Promotion of interdisciplinary pilot projects ...   \n",
      "\n",
      "                         procedure            source  \\\n",
      "1  procedure information not found  foerderdatenbank   \n",
      "3  procedure information not found  foerderdatenbank   \n",
      "\n",
      "                                                 url deadline_date  days_left  \\\n",
      "1  https://www.foerderdatenbank.de/FDB/Content/DE...           NaT        NaN   \n",
      "3  https://www.foerderdatenbank.de/FDB/Content/DE...           NaT        NaN   \n",
      "\n",
      "   relevance_score  \n",
      "1               50  \n",
      "3               10  \n"
     ]
    }
   ],
   "source": [
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bc59c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ No relevant results found. Unable to generate recommendations based on data.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Optionally generate GPT output with a fallback prompt or skip LLM call.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Proceed with formatting and LLM completion\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     semantic_output = \u001b[43mgenerate_structured_funding_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(semantic_output)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mgenerate_structured_funding_blocks\u001b[39m\u001b[34m(matches, user_query)\u001b[39m\n\u001b[32m      6\u001b[39m field_aliases = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAmount\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhow much\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmoney\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDeadline\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mdeadline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlast date\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33muntil\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msubmission date\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContact\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mcontact\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33memail\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mperson\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msupport\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m }\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(matches, start=\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     meta = \u001b[43mmatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m     name = meta.get(\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnnamed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m     fields = {\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDescription\u001b[39m\u001b[33m\"\u001b[39m: meta.get(\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDomain\u001b[39m\u001b[33m\"\u001b[39m: meta.get(\u001b[33m\"\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m\"\u001b[39m: meta.get(\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m     }\n",
      "\u001b[31mKeyError\u001b[39m: 'metadata'"
     ]
    }
   ],
   "source": [
    "def generate_structured_funding_blocks(matches, user_query: str) -> str:\n",
    "    formatted_blocks = []\n",
    "\n",
    "    field_aliases = {\n",
    "        \"Amount\": [\"amount\", \"how much\", \"funding\", \"money\"],\n",
    "        \"Deadline\": [\"deadline\", \"last date\", \"until\", \"submission date\"],\n",
    "        \"Eligibility\": [\"eligible\", \"eligibility\", \"who can apply\"],\n",
    "        \"Procedure\": [\"procedure\", \"how to apply\", \"application\", \"steps\", \"process\"],\n",
    "        \"Contact\": [\"contact\", \"email\", \"person\", \"support\"],\n",
    "    }\n",
    "\n",
    "    for idx, meta in enumerate(matches, start=1):\n",
    "        # 'meta' is directly the dict with funding info\n",
    "        name = meta.get(\"name\", \"Unnamed\")\n",
    "        fields = {\n",
    "            \"Description\": meta.get(\"description\"),\n",
    "            \"Domain\": meta.get(\"domain\"),\n",
    "            \"Eligibility\": meta.get(\"eligibility\"),\n",
    "            \"Amount\": meta.get(\"amount\"),\n",
    "            \"Deadline\": meta.get(\"deadline\"),\n",
    "            \"Procedure\": meta.get(\"procedure\"),\n",
    "            \"Location\": meta.get(\"location\"),\n",
    "            \"Contact\": meta.get(\"contact\"),\n",
    "            \"URL\": meta.get(\"url\"),\n",
    "            \"Source\": meta.get(\"source\", \"Unknown\")\n",
    "        }\n",
    "        block = f\"**{idx}. {name}**\\n\"\n",
    "        for key, val in fields.items():\n",
    "            if key == \"Deadline\":\n",
    "                deadline_val = val\n",
    "                if deadline_val is None or pd.isna(deadline_val) or \"not found\" in str(deadline_val).lower():\n",
    "                    deadline_str = \"Not specified\"\n",
    "                else:\n",
    "                    days_left = meta.get(\"days_left\", None)\n",
    "                    if pd.notnull(days_left):\n",
    "                        deadline_str = f\"{deadline_val} (🕒 {int(days_left)} days left)\"\n",
    "                    else:\n",
    "                        deadline_str = deadline_val\n",
    "                block += f\"   - **Deadline**: {deadline_str}\\n\"\n",
    "                continue\n",
    "            if val and \"not found\" not in str(val).lower():\n",
    "                block += f\"   - **{key}**: {val}\\n\"\n",
    "        if fields[\"URL\"]:\n",
    "            block += f\"   - **For more information visit**: {fields['URL']}\\n\"\n",
    "        formatted_blocks.append(block + \"\\n\")  # <-- Add blank line between blocks\n",
    "    return \"\\n\".join(formatted_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d6ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_output = generate_structured_funding_blocks(matches, query)\n",
    "# Display the structured output\n",
    "print(\"Structured Funding Matches:\\n\")\n",
    "display(semantic_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4440d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Prepare prompt for GPT recommendation generation (you can customize further)\n",
    "llm_prompt = f\"\"\"\n",
    "The company described itself as:\n",
    "\n",
    "\"{query}\"\n",
    "\n",
    "Here are the top 5 most relevant public funding programs in Germany, based on a semantic search match to their needs:\n",
    "\n",
    "{semantic_output}\n",
    "\n",
    "Now:\n",
    "\n",
    "Please write a concise and professional recommendation containing **only the top 2–3 most relevant funding programs** in this format:\n",
    "\n",
    "Only select the top programs that most directly match the company’s domain, maturity stage (e.g., early-stage research), or funding needs. Ignore entries that are vague or poorly aligned.\n",
    "\n",
    "For each recommendation, follow this format exactly:\n",
    "\n",
    "1. <Program Name> (Source) \n",
    "**Why it fits**: <1–2 lines explaining relevance to the company’s domain (or) industry (or) field of work>  \n",
    "**Description**: <Brief summary of the program’s goal and what it funds>\n",
    "**Domain**: <Domain>      \n",
    "**Eligibility**: <Eligibility>  \n",
    "**Amount**: <Amount>  \n",
    "**Deadline**: <Deadline (date or timeframe)>\n",
    "**Location**: <Location or applicable regions>  \n",
    "**Contact**: <Contact person, email, or organization>  \n",
    "**Next Steps**:  \n",
    "- Step 1: [Visit the (source) official page:]({{url}})  \n",
    "- Step 2: <One key action the company must take>  \n",
    "- Step 3: <Another action (e.g., submit proposal, form consortium)>  \n",
    "\n",
    "If any field like **Amount**, **Deadline**, **Eligibility**, **Procedure**, or **Contact** is missing, either omit the line or say “Not specified”.\n",
    "\n",
    "Use simple bullet points under **Next Steps**. Only list the top 2 or 3 programs — not all 5.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "227f129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate GPT recommendation using chat completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in funding opportunities.\"},\n",
    "        {\"role\": \"user\", \"content\": llm_prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89091d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧾 GPT Recommendation:\n",
      "\n",
      "1. **Promotion of interdisciplinary pilot projects on the topic of \"Neurobiologically inspired artificial intelligence\"** (foerderdatenbank)  \n",
      "   **Why it fits**: Directly aligns with the AI focus of the company, particularly if their work integrates or is inspired by neurobiological concepts.  \n",
      "   **Description**: Funding for projects that explore the intersection of neurobiology and artificial intelligence to inspire new AI methodologies.  \n",
      "   **Domain**: Research & Innovation (topic-specific)  \n",
      "   **Eligibility**: Research institution, university, company  \n",
      "   **Amount**: Not specified  \n",
      "   **Deadline**: Not specified  \n",
      "   **Location**: Nationwide  \n",
      "   **Contact**: DLR Projektträger, ge@dlr.de, Tel: +49 0228 3821-1210  \n",
      "   **Next Steps**:  \n",
      "   - Step 1: [Visit the official page](https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/bmbf-neurobiologisch-inspirierte-ki.html)  \n",
      "   - Step 2: Review application guidelines and project compatibility  \n",
      "   - Step 3: Prepare a detailed project proposal focusing on innovative AI technologies inspired by neurobiology\n",
      "\n",
      "2. **Funding for projects on the topic of \"Application of artificial intelligence (AI) in drug discovery\"** (foerderdatenbank)  \n",
      "   **Why it fits**: Suitable if the company plans to apply its AI robotics technology in healthcare, specifically for drug discovery involving AI.  \n",
      "   **Description**: Supports projects that apply AI technologies to accelerate the drug discovery process, potentially relevant if the company's AI can be adapted to such applications.  \n",
      "   **Domain**: Research & Innovation (topic-specific), Health & Social Affairs  \n",
      "   **Eligibility**: University, research institution, company, association  \n",
      "   **Amount**: Not specified  \n",
      "   **Deadline**: Not specified  \n",
      "   **Location**: Nationwide  \n",
      "   **Contact**: Projektträger Jülich (PtJ), ptj@fz-juelich.de, Tel: +49 2461 61-2626  \n",
      "   **Next Steps**:  \n",
      "   - Step 1: [Visit the official page](https://www.foerderdatenbank.de/FDB/Content/DE/Foerderprogramm/Bund/BMBF/anwendung-ki-wirkstoffforschung.html)  \n",
      "   - Step 2: Assess the potential to pivot or extend AI capabilities to drug discovery  \n",
      "   - Step 3: Contact PtJ for detailed application procedures and requirements\n",
      "\n",
      "These tailored recommendations are selected to align closely with the company's current focus and potential areas of expansion within AI and robotics research.\n"
     ]
    }
   ],
   "source": [
    "# Print GPT recommendation output\n",
    "print(\"\\n🧾 GPT Recommendation:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
