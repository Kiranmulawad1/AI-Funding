{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd89359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -q openai pinecone python-dotenv pandas tqdm tenacity tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6da0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526e878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables (adjust path if your .env is not in cwd)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29ee60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "assert OPENAI_API_KEY, \"Missing OPENAI_API_KEY\"\n",
    "assert PINECONE_API_KEY, \"Missing PINECONE_API_KEY\"\n",
    "assert PINECONE_ENV, \"Missing PINECONE_ENV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pinecone client instance FIRST\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Index parameters\n",
    "index_name = \"funding-search\"\n",
    "dimension = 1536  # For text-embedding-3-small\n",
    "\n",
    "# List indexes using the client\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        environment=PINECONE_ENV,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47924e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the index (if you need the Index object later)\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfa3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load funding dataset\n",
    "df = pd.read_csv(\"/Users/kiranmulawad/AI-Funding/2_preprocessing/data/merged_funding_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c1b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build semantic_corpus field combining info for embedding\n",
    "def build_semantic_corpus(row):\n",
    "    parts = []\n",
    "    for field in [\"name\", \"description\", \"domain\", \"eligibility\", \"amount\", \"location\", \"procedure\", \"contact\", \"deadline\"]:\n",
    "        val = row.get(field, \"\")\n",
    "        if val:\n",
    "            parts.append(f\"{field} = {val}\")\n",
    "    return \". \".join(parts).strip(\". \")\n",
    "\n",
    "df[\"semantic_corpus\"] = df.apply(build_semantic_corpus, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fcb5e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     semantic_corpus\n",
      "0  name = FORTIS 1st Open Call. description = FOR...\n",
      "1  name = MASTER 2nd Open Call. description = MAS...\n",
      "2  name = PEDVolution Open Call. description = PE...\n",
      "3  name = SMURF 2nd Open Call. description = The ...\n",
      "4  name = GUARDIANS 1st Open Call. description = ...\n"
     ]
    }
   ],
   "source": [
    "# Display the first few semantic_corpus entries as a DataFrame\n",
    "print(df[[\"semantic_corpus\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e522b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token counting to respect OpenAI limits (~8192 tokens)\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "df[\"token_count\"] = df[\"semantic_corpus\"].apply(lambda txt: len(tokenizer.encode(txt)))\n",
    "max_token_limit = 8192\n",
    "too_long = df[df[\"token_count\"] > max_token_limit]\n",
    "if not too_long.empty:\n",
    "    print(f\"⚠️ WARNING: {len(too_long)} rows exceed {max_token_limit} tokens and may cause API errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213f351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stable IDs using hash on URL (or fallback)\n",
    "def hash_id(text):\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "df[\"id\"] = df[\"url\"].fillna(\"no-url\").apply(hash_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c267432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def get_embedding(text: str):\n",
    "    response = client.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb62a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading embeddings to Pinecone:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading embeddings to Pinecone: 100%|██████████| 3/3 [00:29<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded 79 embeddings to Pinecone index 'funding-search' under namespace 'openai-v3'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Upsert embeddings to Pinecone in batches\n",
    "batch_size = 32\n",
    "namespace = \"openai-v3\"  # Your namespace in Pinecone\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size), desc=\"Uploading embeddings to Pinecone\"):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    texts = batch[\"semantic_corpus\"].fillna(\"\").tolist()\n",
    "    ids = batch[\"id\"].tolist()\n",
    "    embeddings = [get_embedding(text) for text in texts]\n",
    "\n",
    "    metadata = batch[[\n",
    "        \"id\", \"name\", \"description\", \"domain\", \"eligibility\", \"location\",\n",
    "        \"amount\", \"procedure\", \"contact\", \"deadline\", \"url\", \"source\"\n",
    "    ]].fillna(\"\").to_dict(orient=\"records\")\n",
    "\n",
    "    vectors = list(zip(ids, embeddings, metadata))\n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "\n",
    "print(f\"✅ Uploaded {len(df)} embeddings to Pinecone index '{index_name}' under namespace '{namespace}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72a1b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'openai-v3': {'vector_count': 79}},\n",
      " 'total_vector_count': 79,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "stats = index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce92180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
