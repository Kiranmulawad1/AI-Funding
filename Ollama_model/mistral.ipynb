{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af88c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Install required packages (run only if not already installed)\n",
    "!pip install -q sentence-transformers pinecone-client python-dotenv pandas ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd6e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9b3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Load API keys and environment variables from .env file\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "assert PINECONE_API_KEY and PINECONE_ENV, \"Pinecone API key or environment not found in .env!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b573a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize Pinecone client and connect to your index\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"funding-search\"\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1ae691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load the embedding model ONCE for efficiency\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee8d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Retrieve top-k relevant funding programs from Pinecone for a given query\n",
    "def retrieve_docs(query, top_k=5, model=embedding_model):\n",
    "    \"\"\"\n",
    "    Retrieve top-k relevant funding programs from Pinecone for a given query.\n",
    "    Returns a list of formatted strings for LLM context.\n",
    "    \"\"\"\n",
    "    # Encode the query to get its vector\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    # Query Pinecone for top-k matches\n",
    "    search_results = index.query(vector=query_vector, top_k=top_k, include_metadata=True)\n",
    "    docs = []\n",
    "    for match in search_results.get(\"matches\", []):\n",
    "        meta = match.get(\"metadata\", {}) or {}\n",
    "        doc_text = (\n",
    "            f\"Name: {meta.get('name', '')}\\n\"\n",
    "            f\"Description: {meta.get('description', '')}\\n\"\n",
    "            f\"Eligibility: {meta.get('eligibility', '')}\\n\"\n",
    "            f\"Amount: {meta.get('amount', '')}\\n\"\n",
    "            f\"Domain: {meta.get('domain', '')}\\n\"\n",
    "            f\"Location: {meta.get('location', '')}\\n\"\n",
    "            f\"Procedure: {meta.get('procedure', '')}\\n\"\n",
    "            f\"URL: {meta.get('url', '')}\\n\"\n",
    "            f\"Source: {meta.get('source', '')}\"\n",
    "        )\n",
    "        docs.append(doc_text)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc32538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate a RAG answer using Mistral via Ollama's chat API\n",
    "def rag_answer(query, top_k=5, model_name=\"mistral\"):\n",
    "    \"\"\"\n",
    "    Generate a RAG answer for a user's query using Pinecone retrieval and Mistral LLM via Ollama.\n",
    "    Uses the chat API for better instruction following.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant funding documents\n",
    "    docs = retrieve_docs(query, top_k=top_k)\n",
    "    # Combine docs as context for the LLM\n",
    "    context = \"\\n\\n\".join(docs)\n",
    "    # Compose a clear, instruction-focused prompt\n",
    "    prompt = (\n",
    "        \"You are an expert on public funding for businesses in Germany. \"\n",
    "        \"Based only on the following funding program data, answer the user's question concisely and factually. \"\n",
    "        \"If the answer is not present in the data, say so.\\n\\n\"\n",
    "        f\"Funding programs:\\n{context}\\n\\n\"\n",
    "        f\"User question: {query}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    # Use Ollama's chat API for better context handling\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    # Return the generated answer text\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7002f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many funding programs are available in Germany for robotics, and what are their names?\n",
      "A:  There is one funding program named \"Research and development (InnoTop)\" available in Rhineland-Palatinate, Germany that supports projects related to robotics. However, it's important to note that other regions within Germany might offer different funding programs for the same domain. For more comprehensive information about available funding options across all of Germany, I would recommend visiting the official German Federal Ministry of Education and Research (BMBF) website or a database like the one provided by the \"FÃ¶rderdatenbank\" linked in your question.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Example usage: Ask a question and get a concise, grounded answer\n",
    "query = \"How many funding programs are available in Germany for robotics, and what are their names?\"\n",
    "answer = rag_answer(query, top_k=5, model_name=\"mistral\")  # Use \"mistral\" or \"mixtral\" as installed\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Optional: Table-based semantic search for UI or analysis\n",
    "def semantic_search(query, top_k=5, model=embedding_model):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame of the top-k relevant funding programs for a given query.\n",
    "    \"\"\"\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    search_results = index.query(vector=query_vector, top_k=top_k, include_metadata=True)\n",
    "    matches = search_results.get(\"matches\", [])\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        meta = match.get(\"metadata\", {}) or {}\n",
    "        results.append({\n",
    "            \"name\": meta.get(\"name\", \"\"),\n",
    "            \"description\": meta.get(\"description\", \"\"),\n",
    "            \"eligibility\": meta.get(\"eligibility\", \"\"),\n",
    "            \"amount\": meta.get(\"amount\", \"\"),\n",
    "            \"domain\": meta.get(\"domain\", \"\"),\n",
    "            \"location\": meta.get(\"location\", \"\"),\n",
    "            \"procedure\": meta.get(\"procedure\", \"\"),\n",
    "            \"url\": meta.get(\"url\", \"\"),\n",
    "            \"source\": meta.get(\"source\", \"\"),\n",
    "            \"score\": match.get(\"score\", None)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ace9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Example: Display search results as a table\n",
    "results_df = semantic_search(\"AI funding support for tech startups in Germany\", top_k=5)\n",
    "display(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
