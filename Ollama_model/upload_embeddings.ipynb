{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b69133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_upload_embeddings.ipynb\n",
    "\n",
    "# %%\n",
    "# Install necessary packages (run only if not already installed)\n",
    "!pip install -q sentence-transformers pinecone-client python-dotenv pandas tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149c92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667268b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "assert PINECONE_API_KEY and PINECONE_ENV, \"Pinecone API key or environment not found in .env!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad6362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load your merged funding data CSV\n",
    "df = pd.read_csv(\"/Users/kiranmulawad/AI-Funding/2_preprocessing/data/merged_funding_data.csv\")  # Adjust the path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30215a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Build a semantic_corpus column by combining relevant fields for semantic search\n",
    "def build_corpus(row):\n",
    "    fields = [\n",
    "        row.get(\"name\", \"\"),\n",
    "        row.get(\"description\", \"\"),\n",
    "        row.get(\"domain\", \"\"),\n",
    "        row.get(\"eligibility\", \"\"),\n",
    "        row.get(\"amount\", \"\"),\n",
    "        row.get(\"location\", \"\"),\n",
    "        row.get(\"procedure\", \"\"),\n",
    "    ]\n",
    "    # Join non-empty fields with \". \"\n",
    "    return \". \".join([str(f) for f in fields if pd.notna(f) and str(f).strip()])\n",
    "\n",
    "df[\"semantic_corpus\"] = df.apply(build_corpus, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb15864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize the embedding model (MiniLM is fast and good for semantic search)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b5b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Initialize Pinecone client and create index if needed\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"funding-search\"\n",
    "dimension = 384  # Dimension for MiniLM-L6-v2 embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c45d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index only if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "    )\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21614ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Pinecone: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All embeddings uploaded to Pinecone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Batch upload embeddings and metadata to Pinecone\n",
    "batch_size = 100  # Adjust batch size for your memory/connection\n",
    "for i in tqdm(range(0, len(df), batch_size), desc=\"Uploading to Pinecone\"):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    # Encode the semantic_corpus column to get embeddings\n",
    "    embeddings = model.encode(batch[\"semantic_corpus\"].tolist(), show_progress_bar=False).tolist()\n",
    "    # Use a stable, unique ID (here: hash of URL)\n",
    "    ids = batch[\"url\"].apply(lambda x: f\"id-{hash(x)}\").tolist()\n",
    "    # Include all relevant metadata fields for later retrieval\n",
    "    metadata = batch[[\"name\", \"description\", \"eligibility\", \"amount\", \"domain\", \"location\", \"procedure\", \"url\", \"source\"]].fillna(\"\").to_dict(orient=\"records\")\n",
    "    # Prepare data for upsert\n",
    "    to_upsert = list(zip(ids, embeddings, metadata))\n",
    "    # Upload to Pinecone\n",
    "    index.upsert(vectors=to_upsert)\n",
    "\n",
    "print(\"✅ All embeddings uploaded to Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326c57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
