{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6fb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from ollama import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b6f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037a2467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01132d8ba7c74a608c3fa0aa558180e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900ab3615d2a4651b7dc719ee42bace5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6e42562ebd459c94377063ef4207b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90afd089b044c74afd9f46a6d1fa175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b397d4682c14d348e0f16752bf013e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23cdc8bceb04c359f2365daf3abc658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6f388aa09b4a688b39e1eab428f7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Initialize clients\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"funding-search-bge\")\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "rerank_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "ollama_client = Client(host=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385f39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Input query\n",
    "query = \"We are an AI company focused on AI for robotics. We are focusing on research right now.\"\n",
    "query_embedding = embed_model.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c09677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Get semantic matches from Pinecone\n",
    "semantic_matches = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=8,\n",
    "    include_metadata=True,\n",
    "    namespace=\"open-source-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in semantic_matches[\"matches\"]:\n",
    "    print(match[\"metadata\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2bfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Rerank using CrossEncoder\n",
    "rerank_inputs = [\n",
    "    [query, match[\"metadata\"].get(\"description\", \"\")] for match in semantic_matches[\"matches\"]\n",
    "]\n",
    "scores = rerank_model.predict(rerank_inputs)\n",
    "reranked = [x for _, x in sorted(zip(scores, semantic_matches[\"matches\"]), reverse=True)]\n",
    "top_matches = reranked[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48661c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Format structured funding blocks with citations\n",
    "def generate_funding_blocks(matches, user_query: str) -> str:\n",
    "    formatted = []\n",
    "    for idx, match in enumerate(matches, start=1):\n",
    "        meta = match[\"metadata\"]\n",
    "        name = meta.get(\"name\", f\"Program {idx}\")\n",
    "        block = f\"\"\"**{idx}. {name}**\\n\"\"\"\n",
    "        fields = {\n",
    "            \"Description\": meta.get(\"description\"),\n",
    "            \"Domain\": meta.get(\"domain\"),\n",
    "            \"Eligibility\": meta.get(\"eligibility\"),\n",
    "            \"Amount\": meta.get(\"amount\"),\n",
    "            \"Deadline\": meta.get(\"deadline\"),\n",
    "            \"Procedure\": meta.get(\"procedure\"),\n",
    "            \"Contact\": meta.get(\"contact\"),\n",
    "            \"URL\": meta.get(\"url\")\n",
    "        }\n",
    "        for key, val in fields.items():\n",
    "            if val and \"not found\" not in str(val).lower():\n",
    "                block += f\"- **{key}**: {val}\\n\"\n",
    "        block += \"\\n\"\n",
    "        formatted.append(block)\n",
    "    return \"\\n\".join(formatted).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c62c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Results:\n",
      " **1. AIRISE Open Call**\n",
      "- **Description**: AIRISE supports SMEs and mid-caps in the implementation and scaling of AI solutions in manufacturing. The Open Calls are aimed at companies that are either conducting their first AI experiments or want to bring existing applications to a higher level of maturity (TRL). Funding is available for projects in areas such as design & engineering, process monitoring, manufacturing operations, supply chain, cyber security and training Further information can be found here\n",
      "- **Domain**: AI in production\n",
      "- **Eligibility**: SMEs and mid-caps\n",
      "- **Amount**: Up to 60,000 euros\n",
      "- **Deadline**: July 16, 2025\n",
      "- **URL**: https://airise.eu/calls\n",
      "\n",
      "\n",
      "**2. Funding of collaborative research projects in the fields of \"software and algorithms with a focus on artificial intelligence and machine learning\", \"research data management\" and \"federated digital infrastructures\" for the exploration of the universe and matter (ErUM)**\n",
      "- **Description**: Directive on the funding  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "semantic_output = generate_funding_blocks(top_matches, query)\n",
    "print(\"üîç Top Results:\\n\", semantic_output[:1000], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540430b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load the advanced prompt template\n",
    "with open(\"llm_prompt_llama_advanced.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "llm_prompt = prompt_template.replace(\"{{QUERY}}\", query).replace(\"{{RESULTS}}\", semantic_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a50e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Generate recommendation using LLaMA 3.2\n",
    "response = ollama_client.generate(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=llm_prompt,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Print final output\n",
    "print(\"üßæ Final Recommendation:\\n\")\n",
    "print(response[\"response\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
